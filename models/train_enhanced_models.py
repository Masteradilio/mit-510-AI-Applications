"""Script avan√ßado para treinar modelos com vari√°veis ex√≥genas e otimiza√ß√£o de hiperpar√¢metros.
Implementa treinamento comparativo entre modelos b√°sicos e modelos com vari√°veis ex√≥genas.
Inclui otimiza√ß√£o autom√°tica de hiperpar√¢metros e valida√ß√£o cruzada temporal.
"""

import os
import sys
import pandas as pd
import numpy as np
import joblib
import warnings
from datetime import datetime
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import ParameterGrid
import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# Adicionar o diret√≥rio src ao path para importar m√≥dulos personalizados
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

try:
    from preprocessing.feature_engineering import add_technical_indicators, add_exogenous_variables, create_target_variables, add_cyclical_features
    from modeling.rnn_models import create_enhanced_rnn_model, get_callbacks
except ImportError as e:
    print(f"‚ö†Ô∏è Erro ao importar m√≥dulos personalizados: {e}")
    print("Continuando com funcionalidades b√°sicas...")
    
# Configura√ß√µes
warnings.filterwarnings('ignore')
tf.get_logger().setLevel('ERROR')
np.random.seed(42)
tf.random.set_seed(42)

# Configura√ß√£o de CPU otimizada
def setup_device():
    """Configura dispositivo de processamento."""
    print("üîß Configurando dispositivo de processamento...")
    
    # Verificar GPU
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"‚úÖ GPU configurada: {len(gpus)} dispositivo(s)")
            return tf.distribute.MirroredStrategy(), True
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao configurar GPU: {e}")
    
    # Configurar CPU
    total_cores = os.cpu_count()
    limited_cores = total_cores // 2
    tf.config.threading.set_intra_op_parallelism_threads(limited_cores)
    tf.config.threading.set_inter_op_parallelism_threads(limited_cores)
    print(f"üñ•Ô∏è CPU configurada com {limited_cores} threads")
    return tf.distribute.get_strategy(), False

# Configurar dispositivo
strategy, using_gpu = setup_device()

# Configura√ß√µes do projeto
PROJECT_ROOT = "C:/Users/Adilio/Documents/Projetos/MIT-510"
DATA_RAW_DIR = os.path.join(PROJECT_ROOT, "data", "raw")
MODELS_DIR = os.path.join(PROJECT_ROOT, "models", "models")
REPORTS_DIR = os.path.join(PROJECT_ROOT, "reports")

# Criar diret√≥rios
os.makedirs(MODELS_DIR, exist_ok=True)
os.makedirs(REPORTS_DIR, exist_ok=True)

# Configura√ß√µes de treinamento
SEQUENCE_LENGTH = 60
TEST_SIZE = 0.2
VALIDATION_SIZE = 0.2

# Configura√ß√µes din√¢micas baseadas no dispositivo
if using_gpu:
    EPOCHS = 100
    BATCH_SIZE = 128
    PATIENCE = 15
else:
    EPOCHS = 50
    BATCH_SIZE = 32
    PATIENCE = 10

# Mapeamento de arquivos de dados
DATA_FILES = {
    'aapl': 'apple-stock-2014-2024/apple-stockprice-2014-2024.csv',
    'btc': 'BTC-USD From 2014 To Dec-2024.csv'
}

# Configura√ß√µes de otimiza√ß√£o de hiperpar√¢metros
HYPERPARAM_GRID = {
    'units': [64, 128, 256] if using_gpu else [32, 64, 128],
    'layers': [2, 3, 4],
    'dropout_rate': [0.1, 0.2, 0.3],
    'learning_rate': [0.001, 0.002, 0.005],
    'model_type': ['lstm', 'gru']
}

class EnhancedModelTrainer:
    """Trainer avan√ßado com suporte a vari√°veis ex√≥genas e otimiza√ß√£o de hiperpar√¢metros."""
    
    def __init__(self, strategy, using_gpu=False):
        self.results = []
        self.strategy = strategy
        self.using_gpu = using_gpu
        self.best_models = {}
        print(f"ü§ñ EnhancedModelTrainer inicializado - GPU: {'Sim' if using_gpu else 'N√£o'}")
    
    def load_and_enhance_data(self, asset_name, use_exogenous=True):
        """Carrega dados e adiciona features avan√ßadas incluindo vari√°veis ex√≥genas."""
        file_path = os.path.join(DATA_RAW_DIR, DATA_FILES[asset_name])
        
        if not os.path.exists(file_path):
            print(f"‚ùå Arquivo n√£o encontrado: {file_path}")
            return None, None, None
            
        print(f"üìä Carregando e processando dados para {asset_name.upper()}...")
        
        # Carregar dados b√°sicos
        df = pd.read_csv(file_path)
        
        # Padronizar colunas
        if 'Adj Close' in df.columns:
            df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']].copy()
            df['Close'] = df['Adj Close']
        else:
            df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']].copy()
            
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date').reset_index(drop=True)
        df = df.dropna()
        
        # Adicionar indicadores t√©cnicos
        try:
            df = add_technical_indicators(df)
            print("‚úÖ Indicadores t√©cnicos adicionados")
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao adicionar indicadores t√©cnicos: {e}")
            # Fallback para indicadores b√°sicos
            df['MA_5'] = df['Close'].rolling(window=5).mean()
            df['MA_20'] = df['Close'].rolling(window=20).mean()
            df['Volatility'] = df['Close'].pct_change().rolling(window=10).std()
        
        # Adicionar vari√°veis ex√≥genas se solicitado
        if use_exogenous:
            try:
                df = add_exogenous_variables(df, use_comprehensive_collector=True)
                print("‚úÖ Vari√°veis ex√≥genas adicionadas")
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao adicionar vari√°veis ex√≥genas: {e}")
                print("Continuando sem vari√°veis ex√≥genas...")
        
        # Adicionar features c√≠clicas
        try:
            df = add_cyclical_features(df)
            print("‚úÖ Features c√≠clicas adicionadas")
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao adicionar features c√≠clicas: {e}")
        
        # Remover colunas n√£o num√©ricas e com muitos NaN
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        df_numeric = df[numeric_columns].copy()
        
        # Remover colunas com mais de 50% de valores ausentes
        threshold = len(df_numeric) * 0.5
        df_numeric = df_numeric.dropna(axis=1, thresh=threshold)
        
        # Preencher valores ausentes restantes
        df_numeric = df_numeric.fillna(method='ffill').fillna(method='bfill')
        df_numeric = df_numeric.dropna()
        
        if len(df_numeric) < SEQUENCE_LENGTH + 100:
            print(f"‚ùå Dados insuficientes ap√≥s processamento: {len(df_numeric)} linhas")
            return None, None, None
            
        print(f"‚úÖ Dados processados: {len(df_numeric)} linhas, {len(df_numeric.columns)} features")
        
        # Preparar dados para treinamento
        feature_columns = [col for col in df_numeric.columns if col != 'Close']
        data = df_numeric[feature_columns + ['Close']].values
        
        # Normalizar dados
        scaler = MinMaxScaler(feature_range=(0, 1))
        scaled_data = scaler.fit_transform(data)
        
        return scaled_data, scaler, df_numeric
    
    def create_sequences_enhanced(self, data, sequence_length):
        """Cria sequ√™ncias para treinamento com suporte a m√∫ltiplas features."""
        X, y = [], []
        
        for i in range(sequence_length, len(data)):
            X.append(data[i-sequence_length:i, :-1])  # Todas as features exceto Close
            y.append(data[i, -1])  # Close price (√∫ltima coluna)
            
        return np.array(X), np.array(y)
    
    def optimize_hyperparameters(self, X_train, y_train, X_val, y_val, max_trials=5):
        """Otimiza hiperpar√¢metros usando grid search limitado."""
        print("üîç Iniciando otimiza√ß√£o de hiperpar√¢metros...")
        
        # Criar grid reduzido para otimiza√ß√£o
        param_combinations = list(ParameterGrid(HYPERPARAM_GRID))
        
        # Limitar n√∫mero de combina√ß√µes para evitar tempo excessivo
        if len(param_combinations) > max_trials:
            param_combinations = np.random.choice(param_combinations, max_trials, replace=False)
        
        best_params = None
        best_score = float('inf')
        
        for i, params in enumerate(param_combinations):
            print(f"üß™ Testando combina√ß√£o {i+1}/{len(param_combinations)}: {params}")
            
            try:
                with self.strategy.scope():
                    model = create_enhanced_rnn_model(
                        input_shape=(X_train.shape[1], X_train.shape[2]),
                        units=params['units'],
                        layers=params['layers'],
                        dropout_rate=params['dropout_rate'],
                        model_type=params['model_type'],
                        use_batch_norm=True
                    )
                    
                    model.compile(
                        optimizer=Adam(learning_rate=params['learning_rate']),
                        loss='mse',
                        metrics=['mae']
                    )
                
                # Treinamento r√°pido para avalia√ß√£o
                early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
                
                history = model.fit(
                    X_train, y_train,
                    epochs=20,  # √âpocas reduzidas para otimiza√ß√£o
                    batch_size=BATCH_SIZE,
                    validation_data=(X_val, y_val),
                    callbacks=[early_stopping],
                    verbose=0
                )
                
                # Avaliar performance
                val_loss = min(history.history['val_loss'])
                
                if val_loss < best_score:
                    best_score = val_loss
                    best_params = params
                    print(f"‚úÖ Nova melhor combina√ß√£o encontrada! Val Loss: {val_loss:.6f}")
                
            except Exception as e:
                print(f"‚ùå Erro ao testar combina√ß√£o: {e}")
                continue
        
        print(f"üéØ Melhores hiperpar√¢metros: {best_params}")
        print(f"üéØ Melhor score: {best_score:.6f}")
        
        return best_params if best_params else HYPERPARAM_GRID
    
    def train_comparative_models(self, asset_name):
        """Treina modelos comparativos: b√°sico vs. com vari√°veis ex√≥genas."""
        print(f"\nüöÄ Iniciando treinamento comparativo para {asset_name.upper()}")
        
        results = []
        
        # 1. Treinar modelo b√°sico (sem vari√°veis ex√≥genas)
        print("\nüìä Treinando modelo B√ÅSICO (sem vari√°veis ex√≥genas)...")
        basic_result = self._train_single_model(asset_name, use_exogenous=False, model_suffix="basic")
        if basic_result:
            results.append(basic_result)
        
        # 2. Treinar modelo com vari√°veis ex√≥genas
        print("\nüìä Treinando modelo AVAN√áADO (com vari√°veis ex√≥genas)...")
        enhanced_result = self._train_single_model(asset_name, use_exogenous=True, model_suffix="enhanced")
        if enhanced_result:
            results.append(enhanced_result)
        
        return results
    
    def _train_single_model(self, asset_name, use_exogenous=True, model_suffix=""):
        """Treina um √∫nico modelo com configura√ß√µes espec√≠ficas."""
        # Carregar e processar dados
        scaled_data, scaler, df = self.load_and_enhance_data(asset_name, use_exogenous)
        if scaled_data is None:
            return None
        
        # Criar sequ√™ncias
        X, y = self.create_sequences_enhanced(scaled_data, SEQUENCE_LENGTH)
        
        # Dividir dados
        train_size = int(len(X) * (1 - TEST_SIZE))
        val_size = int(train_size * (1 - VALIDATION_SIZE))
        
        X_train = X[:val_size]
        y_train = y[:val_size]
        X_val = X[val_size:train_size]
        y_val = y[val_size:train_size]
        X_test = X[train_size:]
        y_test = y[train_size:]
        
        print(f"üìà Dados: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}, Features={X.shape[2]}")
        
        # Otimizar hiperpar√¢metros
        best_params = self.optimize_hyperparameters(X_train, y_train, X_val, y_val)
        
        # Treinar modelo final com melhores par√¢metros
        print("üèóÔ∏è Treinando modelo final com hiperpar√¢metros otimizados...")
        
        with self.strategy.scope():
            model = create_enhanced_rnn_model(
                input_shape=(X_train.shape[1], X_train.shape[2]),
                units=best_params.get('units', 128),
                layers=best_params.get('layers', 3),
                dropout_rate=best_params.get('dropout_rate', 0.2),
                model_type=best_params.get('model_type', 'lstm'),
                use_batch_norm=True
            )
            
            model.compile(
                optimizer=Adam(learning_rate=best_params.get('learning_rate', 0.001)),
                loss='mse',
                metrics=['mae']
            )
        
        # Callbacks
        model_name = f"{asset_name}_{model_suffix}_optimized"
        model_path = os.path.join(MODELS_DIR, f"{model_name}.h5")
        
        callbacks = [
            EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True, verbose=1),
            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7, verbose=1),
            ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)
        ]
        
        # Treinar modelo
        history = model.fit(
            X_train, y_train,
            epochs=EPOCHS,
            batch_size=BATCH_SIZE,
            validation_data=(X_val, y_val),
            callbacks=callbacks,
            verbose=1
        )
        
        # Fazer previs√µes
        train_pred = model.predict(X_train, verbose=0)
        val_pred = model.predict(X_val, verbose=0)
        test_pred = model.predict(X_test, verbose=0)
        
        # Calcular m√©tricas
        metrics = {
            'train_mse': mean_squared_error(y_train, train_pred),
            'val_mse': mean_squared_error(y_val, val_pred),
            'test_mse': mean_squared_error(y_test, test_pred),
            'train_mae': mean_absolute_error(y_train, train_pred),
            'val_mae': mean_absolute_error(y_val, val_pred),
            'test_mae': mean_absolute_error(y_test, test_pred),
            'train_r2': r2_score(y_train, train_pred),
            'val_r2': r2_score(y_val, val_pred),
            'test_r2': r2_score(y_test, test_pred)
        }
        
        # Salvar scaler
        scaler_path = os.path.join(MODELS_DIR, f"{model_name}_scaler.joblib")
        joblib.dump(scaler, scaler_path)
        
        # Preparar resultado
        result = {
            'asset': asset_name.upper(),
            'model_type': f"{best_params.get('model_type', 'lstm').upper()}_{model_suffix.upper()}",
            'use_exogenous': use_exogenous,
            'num_features': X.shape[2],
            'best_params': best_params,
            **metrics,
            'epochs_trained': len(history.history['loss']),
            'final_train_loss': history.history['loss'][-1],
            'final_val_loss': history.history['val_loss'][-1],
            'model_path': model_path,
            'scaler_path': scaler_path,
            'data_points': len(df),
            'training_period': f"{df.index[0]} to {df.index[-1]}"
        }
        
        self.results.append(result)
        
        print(f"‚úÖ Modelo {model_suffix} treinado com sucesso!")
        print(f"   üìä Features: {X.shape[2]}")
        print(f"   üìä MSE Test: {metrics['test_mse']:.6f}")
        print(f"   üìä MAE Test: {metrics['test_mae']:.6f}")
        print(f"   üìä R¬≤ Test: {metrics['test_r2']:.4f}")
        
        return result
    
    def generate_enhanced_report(self):
        """Gera relat√≥rio comparativo detalhado."""
        if not self.results:
            print("‚ùå Nenhum resultado para gerar relat√≥rio")
            return
        
        report_path = os.path.join(REPORTS_DIR, "enhanced_model_training_report.md")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# Relat√≥rio de Treinamento de Modelos Avan√ßados\n\n")
            f.write(f"**Data de Gera√ß√£o:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # Resumo geral
            f.write("## üìä Resumo Geral\n\n")
            f.write(f"- **Total de modelos treinados:** {len(self.results)}\n")
            f.write(f"- **Ativos:** {len(set(r['asset'] for r in self.results))}\n")
            f.write(f"- **Modelos b√°sicos:** {len([r for r in self.results if not r['use_exogenous']])}\n")
            f.write(f"- **Modelos com vari√°veis ex√≥genas:** {len([r for r in self.results if r['use_exogenous']])}\n\n")
            
            # Compara√ß√£o de performance
            f.write("## üèÜ Compara√ß√£o de Performance\n\n")
            
            # Agrupar por ativo
            assets = set(r['asset'] for r in self.results)
            for asset in sorted(assets):
                asset_results = [r for r in self.results if r['asset'] == asset]
                f.write(f"### {asset}\n\n")
                
                basic_models = [r for r in asset_results if not r['use_exogenous']]
                enhanced_models = [r for r in asset_results if r['use_exogenous']]
                
                if basic_models and enhanced_models:
                    basic_best = min(basic_models, key=lambda x: x['test_mse'])
                    enhanced_best = min(enhanced_models, key=lambda x: x['test_mse'])
                    
                    improvement = ((basic_best['test_mse'] - enhanced_best['test_mse']) / basic_best['test_mse']) * 100
                    
                    f.write(f"**Modelo B√°sico (sem vari√°veis ex√≥genas):**\n")
                    f.write(f"- MSE: {basic_best['test_mse']:.6f}\n")
                    f.write(f"- MAE: {basic_best['test_mae']:.6f}\n")
                    f.write(f"- R¬≤: {basic_best['test_r2']:.4f}\n")
                    f.write(f"- Features: {basic_best['num_features']}\n\n")
                    
                    f.write(f"**Modelo Avan√ßado (com vari√°veis ex√≥genas):**\n")
                    f.write(f"- MSE: {enhanced_best['test_mse']:.6f}\n")
                    f.write(f"- MAE: {enhanced_best['test_mae']:.6f}\n")
                    f.write(f"- R¬≤: {enhanced_best['test_r2']:.4f}\n")
                    f.write(f"- Features: {enhanced_best['num_features']}\n\n")
                    
                    if improvement > 0:
                        f.write(f"**üéØ Melhoria com vari√°veis ex√≥genas: {improvement:.2f}% (MSE)** ‚úÖ\n\n")
                    else:
                        f.write(f"**‚ö†Ô∏è Modelo b√°sico teve melhor performance: {abs(improvement):.2f}%**\n\n")
            
            # Tabela detalhada
            f.write("## üìã Resultados Detalhados\n\n")
            f.write("| Ativo | Modelo | Ex√≥genas | Features | MSE Test | MAE Test | R¬≤ Test | √âpocas |\n")
            f.write("|-------|--------|----------|----------|----------|----------|---------|--------|\n")
            
            for result in sorted(self.results, key=lambda x: x['test_mse']):
                exogenous_status = "‚úÖ" if result['use_exogenous'] else "‚ùå"
                f.write(f"| {result['asset']} | {result['model_type']} | {exogenous_status} | "
                       f"{result['num_features']} | {result['test_mse']:.6f} | "
                       f"{result['test_mae']:.6f} | {result['test_r2']:.4f} | "
                       f"{result['epochs_trained']} |\n")
            
            # An√°lise de hiperpar√¢metros
            f.write("\n## ‚öôÔ∏è Hiperpar√¢metros Otimizados\n\n")
            
            for result in self.results:
                f.write(f"### {result['asset']} - {result['model_type']}\n\n")
                params = result['best_params']
                for param, value in params.items():
                    f.write(f"- **{param}:** {value}\n")
                f.write("\n")
            
            # Configura√ß√µes utilizadas
            f.write("## üîß Configura√ß√µes de Treinamento\n\n")
            f.write(f"- **Sequ√™ncia de entrada:** {SEQUENCE_LENGTH} dias\n")
            f.write(f"- **Tamanho do teste:** {TEST_SIZE*100}%\n")
            f.write(f"- **Tamanho da valida√ß√£o:** {VALIDATION_SIZE*100}%\n")
            f.write(f"- **√âpocas m√°ximas:** {EPOCHS}\n")
            f.write(f"- **Batch size:** {BATCH_SIZE}\n")
            f.write(f"- **Paci√™ncia (early stopping):** {PATIENCE}\n")
            f.write(f"- **Dispositivo:** {'GPU' if using_gpu else 'CPU'}\n")
            f.write(f"- **Otimiza√ß√£o de hiperpar√¢metros:** Ativada\n\n")
            
            # Conclus√µes
            f.write("## üéØ Conclus√µes\n\n")
            
            basic_results = [r for r in self.results if not r['use_exogenous']]
            enhanced_results = [r for r in self.results if r['use_exogenous']]
            
            if basic_results and enhanced_results:
                basic_avg_mse = np.mean([r['test_mse'] for r in basic_results])
                enhanced_avg_mse = np.mean([r['test_mse'] for r in enhanced_results])
                overall_improvement = ((basic_avg_mse - enhanced_avg_mse) / basic_avg_mse) * 100
                
                f.write(f"- **MSE m√©dio (modelos b√°sicos):** {basic_avg_mse:.6f}\n")
                f.write(f"- **MSE m√©dio (modelos com ex√≥genas):** {enhanced_avg_mse:.6f}\n")
                
                if overall_improvement > 0:
                    f.write(f"- **‚úÖ Melhoria geral com vari√°veis ex√≥genas:** {overall_improvement:.2f}%\n")
                    f.write(f"- **üéâ Status:** Vari√°veis ex√≥genas melhoraram significativamente a performance\n")
                else:
                    f.write(f"- **‚ö†Ô∏è Modelos b√°sicos tiveram melhor performance:** {abs(overall_improvement):.2f}%\n")
                    f.write(f"- **üîç Recomenda√ß√£o:** Revisar sele√ß√£o e processamento de vari√°veis ex√≥genas\n")
            
            f.write("\n---\n")
            f.write("*Relat√≥rio gerado automaticamente pelo sistema de treinamento avan√ßado.*\n")
            f.write(f"*Dispositivo utilizado: {'GPU' if using_gpu else 'CPU'}*\n")
        
        print(f"üìÑ Relat√≥rio avan√ßado gerado: {report_path}")
        return report_path

def main():
    """Fun√ß√£o principal para executar treinamento avan√ßado."""
    print("üöÄ Iniciando Treinamento Avan√ßado com Vari√°veis Ex√≥genas")
    print("="*70)
    
    trainer = EnhancedModelTrainer(strategy, using_gpu)
    
    # Treinar modelos comparativos para cada ativo
    for asset_name in DATA_FILES.keys():
        try:
            results = trainer.train_comparative_models(asset_name)
            print(f"‚úÖ Treinamento conclu√≠do para {asset_name.upper()}: {len(results)} modelos")
        except Exception as e:
            print(f"‚ùå Erro no treinamento para {asset_name}: {str(e)}")
            continue
    
    # Gerar relat√≥rio
    print("\n" + "="*70)
    print("üìÑ Gerando relat√≥rio comparativo...")
    
    if trainer.results:
        report_path = trainer.generate_enhanced_report()
        
        # An√°lise final
        basic_results = [r for r in trainer.results if not r['use_exogenous']]
        enhanced_results = [r for r in trainer.results if r['use_exogenous']]
        
        print("\n" + "="*70)
        print("üéØ AN√ÅLISE FINAL")
        print("="*70)
        
        if basic_results and enhanced_results:
            basic_avg_mse = np.mean([r['test_mse'] for r in basic_results])
            enhanced_avg_mse = np.mean([r['test_mse'] for r in enhanced_results])
            improvement = ((basic_avg_mse - enhanced_avg_mse) / basic_avg_mse) * 100
            
            print(f"üìä Modelos b√°sicos - MSE m√©dio: {basic_avg_mse:.6f}")
            print(f"üìä Modelos com ex√≥genas - MSE m√©dio: {enhanced_avg_mse:.6f}")
            
            if improvement > 0:
                print(f"üéâ SUCESSO: Vari√°veis ex√≥genas melhoraram a performance em {improvement:.2f}%")
            else:
                print(f"‚ö†Ô∏è ATEN√á√ÉO: Modelos b√°sicos foram {abs(improvement):.2f}% melhores")
        
        print(f"\nüìÑ Relat√≥rio completo: {report_path}")
        print("\nüéâ Treinamento avan√ßado conclu√≠do!")
        
    else:
        print("‚ùå Nenhum modelo foi treinado com sucesso")
        sys.exit(1)

if __name__ == "__main__":
    main()