import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import tensorflow as tf
from tensorflow.keras.models import load_model
import joblib
import os
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Adicionar o diret√≥rio src ao path
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..'))
# sys.path.append(os.path.join(PROJECT_ROOT, 'src')) # Removido se n√£o for estritamente necess√°rio aqui, j√° que estamos em pages

st.title("üìä M√©tricas e Avalia√ß√£o dos Modelos")
st.markdown("---")

# Sidebar para configura√ß√µes
st.sidebar.header("‚öôÔ∏è Configura√ß√µes de Avalia√ß√£o")

# Sele√ß√£o do ativo
asset_options = {
    "Apple (AAPL)": "aapl",
    "Bitcoin (BTC-USD)": "btc"
}

selected_asset_name = st.sidebar.selectbox(
    "Selecione o Ativo:",
    options=list(asset_options.keys()),
    index=0
)
selected_asset_code = asset_options[selected_asset_name]

# Sele√ß√£o do modelo
model_options = {
    "LSTM": "lstm",
    "GRU": "gru",
    "SimpleRNN": "simplernn"
}

selected_model_type = st.sidebar.selectbox(
    "Selecione o Modelo:",
    options=list(model_options.keys()),
    index=0
)
selected_model_code = model_options[selected_model_type]

# Par√¢metros de avalia√ß√£o
st.sidebar.subheader("Par√¢metros de Teste")
test_size = st.sidebar.slider(
    "Tamanho do Conjunto de Teste (%):",
    min_value=10,
    max_value=30,
    value=20,
    step=5
)

forecast_horizon = st.sidebar.selectbox(
    "Horizonte de Previs√£o (dias):",
    options=[1, 3, 5, 7, 14],
    index=2
)

@st.cache_data
def load_processed_data(asset_name):
    """Carrega os dados processados do ativo selecionado."""
    # Corrigir o caminho para ser absoluto
    file_path = os.path.join(PROJECT_ROOT, "data", "processed", f"{asset_name}_processed.csv")
    try:
        df = pd.read_csv(file_path, index_col="Date", parse_dates=True)
        
        # Garantir que temos as colunas b√°sicas necess√°rias
        if 'Adj Close' in df.columns:
            df['Close'] = df['Adj Close']
        
        # Criar features t√©cnicas necess√°rias para compatibilidade com o modelo
        if 'MA_5' not in df.columns:
            df['MA_5'] = df['Close'].rolling(window=5, min_periods=1).mean()
        if 'MA_20' not in df.columns:
            df['MA_20'] = df['Close'].rolling(window=20, min_periods=1).mean()
        if 'Volume_MA' not in df.columns:
            df['Volume_MA'] = df['Volume'].rolling(window=10, min_periods=1).mean()
        
        # Remover valores NaN
        df = df.fillna(method='ffill').fillna(method='bfill')
        
        return df
    except FileNotFoundError:
        st.error(f"Arquivo de dados processados n√£o encontrado para {asset_name.upper()} em {file_path}")
        st.info(f"Verifique se o arquivo existe em: {os.path.abspath(file_path)}")
        return None

@st.cache_resource
def load_model_and_scaler(asset_name, model_type):
    """Carrega o modelo treinado e o scaler."""
    # Corrigir os caminhos para serem absolutos
    model_path = os.path.join(PROJECT_ROOT, "models", "models", f"{asset_name}_{model_type}_best.h5")
    scaler_path = os.path.join(PROJECT_ROOT, "models", "models", f"{asset_name}_scaler.joblib")
    
    model = None
    scaler = None
    
    try:
        model = load_model(model_path)
    except Exception as e:
        st.warning(f"Modelo n√£o encontrado: {model_path}. Erro: {e}")
    
    try:
        scaler = joblib.load(scaler_path)
    except Exception as e:
        st.warning(f"Scaler n√£o encontrado: {scaler_path}. Erro: {e}")
    
    return model, scaler

def prepare_sequences(data, sequence_length=60):
    """Prepara sequ√™ncias para avalia√ß√£o do modelo."""
    model_features = ['Open', 'High', 'Low', 'Close', 'Volume', 'MA_5', 'MA_20', 'Volume_MA']
    
    # Verificar se todas as features necess√°rias existem
    missing_features = [col for col in model_features if col not in data.columns]
    if missing_features:
        st.error(f"Features faltantes: {missing_features}")
        return None, None
    
    # Selecionar apenas as features do modelo
    feature_data = data[model_features].copy()
    
    X, y = [], []
    for i in range(sequence_length, len(feature_data)):
        X.append(feature_data.iloc[i-sequence_length:i].values)
        y.append(feature_data.iloc[i]['Close'])
    
    return np.array(X), np.array(y)

def evaluate_model(model, scaler, X_test, y_test):
    """Avalia o modelo e calcula m√©tricas."""
    if model is None or scaler is None:
        return None
    
    # Normalizar dados de teste
    X_test_scaled = np.array([scaler.transform(seq) for seq in X_test])
    
    # Fazer previs√µes
    predictions_scaled = model.predict(X_test_scaled, verbose=0)
    
    # Desnormalizar previs√µes
    predictions = []
    y_true = []
    
    for i, pred_scaled in enumerate(predictions_scaled):
        # Criar array dummy para desnormaliza√ß√£o
        dummy_pred = np.zeros((1, scaler.n_features_in_))
        dummy_pred[0, 3] = pred_scaled[0] if len(pred_scaled.shape) > 1 else pred_scaled
        pred_denorm = scaler.inverse_transform(dummy_pred)[0, 3]
        predictions.append(pred_denorm)
        
        # Desnormalizar valor real
        dummy_true = np.zeros((1, scaler.n_features_in_))
        dummy_true[0, 3] = (y_test[i] - scaler.data_min_[3]) / (scaler.data_max_[3] - scaler.data_min_[3])
        true_denorm = scaler.inverse_transform(dummy_true)[0, 3]
        y_true.append(true_denorm)
    
    predictions = np.array(predictions)
    y_true = np.array(y_true)
    
    # Calcular m√©tricas
    mse = mean_squared_error(y_true, predictions)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, predictions)
    r2 = r2_score(y_true, predictions)
    
    # M√©tricas espec√≠ficas para previs√£o de pre√ßos
    mape = np.mean(np.abs((y_true - predictions) / y_true)) * 100
    directional_accuracy = np.mean(np.sign(np.diff(y_true)) == np.sign(np.diff(predictions))) * 100
    
    metrics = {
        "MSE": mse,
        "RMSE": rmse,
        "MAE": mae,
        "R¬≤": r2,
        "MAPE (%)": mape,
        "Acur√°cia Direcional (%)": directional_accuracy
    }
    
    return predictions, y_true, metrics

def plot_predictions_vs_actual(predictions, y_true, dates, asset_name, model_type):
    """Plota previs√µes vs valores reais."""
    fig = go.Figure()
    
    # Valores reais
    fig.add_trace(go.Scatter(
        x=dates,
        y=y_true,
        mode='lines',
        name='Valores Reais',
        line=dict(color='blue', width=2)
    ))
    
    # Previs√µes
    fig.add_trace(go.Scatter(
        x=dates,
        y=predictions,
        mode='lines',
        name='Previs√µes',
        line=dict(color='red', width=2)
    ))
    
    fig.update_layout(
        title=f'Previs√µes vs Valores Reais - {asset_name} ({model_type})',
        xaxis_title='Data',
        yaxis_title='Pre√ßo (USD)',
        height=500,
        hovermode='x unified'
    )
    
    return fig

def plot_residuals(predictions, y_true, dates):
    """Plota an√°lise de res√≠duos."""
    residuals = y_true - predictions
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Res√≠duos ao Longo do Tempo', 'Distribui√ß√£o dos Res√≠duos', 
                       'Q-Q Plot', 'Res√≠duos vs Previs√µes'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # Res√≠duos ao longo do tempo
    fig.add_trace(
        go.Scatter(x=dates, y=residuals, mode='lines', name='Res√≠duos'),
        row=1, col=1
    )
    
    # Distribui√ß√£o dos res√≠duos
    fig.add_trace(
        go.Histogram(x=residuals, name='Distribui√ß√£o', nbinsx=30),
        row=1, col=2
    )
    
    # Q-Q Plot (aproximado)
    from scipy import stats
    qq_theoretical = stats.norm.ppf(np.linspace(0.01, 0.99, len(residuals)))
    qq_sample = np.sort(residuals)
    fig.add_trace(
        go.Scatter(x=qq_theoretical, y=qq_sample, mode='markers', name='Q-Q Plot'),
        row=2, col=1
    )
    
    # Res√≠duos vs Previs√µes
    fig.add_trace(
        go.Scatter(x=predictions, y=residuals, mode='markers', name='Res√≠duos vs Pred'),
        row=2, col=2
    )
    
    fig.update_layout(height=600, showlegend=False)
    
    return fig

# Interface principal
st.header(f"üìà Avalia√ß√£o do Modelo {selected_model_type}")
st.subheader(f"Ativo: {selected_asset_name}")

# Carregar dados
with st.spinner(f"Carregando dados de {selected_asset_name}..."):
    df = load_processed_data(selected_asset_code)

if df is not None:
    # Carregar modelo e scaler
    with st.spinner(f"Carregando modelo {selected_model_type}..."):
        model, scaler = load_model_and_scaler(selected_asset_code, selected_model_code)
    
    if model is not None and scaler is not None:
        # Preparar dados de teste
        with st.spinner("Preparando dados de teste..."):
            # Dividir dados
            split_idx = int(len(df) * (1 - test_size/100))
            test_data = df.iloc[split_idx:]
            
            # Preparar sequ√™ncias
            X_test, y_test = prepare_sequences(test_data)
            
            if X_test is not None and y_test is not None:
                # Avaliar modelo
                with st.spinner("Avaliando modelo..."):
                    predictions, y_true, metrics = evaluate_model(model, scaler, X_test, y_test)
                
                if predictions is not None:
                    # Exibir m√©tricas principais
                    st.subheader("üìä M√©tricas de Performance")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("RMSE", f"{metrics['RMSE']:.4f}")
                        st.metric("R¬≤", f"{metrics['R¬≤']:.4f}")
                    
                    with col2:
                        st.metric("MAE", f"{metrics['MAE']:.4f}")
                        st.metric("MAPE (%)", f"{metrics['MAPE (%)']:.2f}%")
                    
                    with col3:
                        st.metric("MSE", f"{metrics['MSE']:.4f}")
                        st.metric("Acur√°cia Direcional", f"{metrics['Acur√°cia Direcional (%)']:.2f}%")
                    
                    # Gr√°fico de previs√µes vs valores reais
                    st.subheader("üìà Previs√µes vs Valores Reais")
                    
                    test_dates = test_data.index[60:]  # Ajustar para sequ√™ncias
                    fig_pred = plot_predictions_vs_actual(
                        predictions, y_true, test_dates, 
                        selected_asset_name, selected_model_type
                    )
                    st.plotly_chart(fig_pred, use_container_width=True)
                    
                    # An√°lise de res√≠duos
                    st.subheader("üìâ An√°lise de Res√≠duos")
                    
                    fig_residuals = plot_residuals(predictions, y_true, test_dates)
                    st.plotly_chart(fig_residuals, use_container_width=True)
                    
                    # Tabela detalhada de m√©tricas
                    st.subheader("üìã M√©tricas Detalhadas")
                    
                    metrics_df = pd.DataFrame({
                        "M√©trica": list(metrics.keys()),
                        "Valor": [f"{v:.4f}" if isinstance(v, float) else str(v) for v in metrics.values()],
                        "Descri√ß√£o": [
                            "Erro Quadr√°tico M√©dio",
                            "Raiz do Erro Quadr√°tico M√©dio",
                            "Erro Absoluto M√©dio",
                            "Coeficiente de Determina√ß√£o",
                            "Erro Percentual Absoluto M√©dio",
                            "% de acerto na dire√ß√£o do movimento"
                        ]
                    })
                    
                    st.dataframe(metrics_df, use_container_width=True)
                    
                    # Estat√≠sticas dos erros
                    st.subheader("üìä Estat√≠sticas dos Erros")
                    
                    errors = y_true - predictions
                    error_stats = {
                        "Erro M√©dio": np.mean(errors),
                        "Desvio Padr√£o dos Erros": np.std(errors),
                        "Erro M√≠nimo": np.min(errors),
                        "Erro M√°ximo": np.max(errors),
                        "Percentil 25": np.percentile(errors, 25),
                        "Mediana dos Erros": np.median(errors),
                        "Percentil 75": np.percentile(errors, 75)
                    }
                    
                    error_df = pd.DataFrame({
                        "Estat√≠stica": list(error_stats.keys()),
                        "Valor": [f"{v:.4f}" for v in error_stats.values()]
                    })
                    
                    st.dataframe(error_df, use_container_width=True)
                    
                else:
                    st.error("Erro ao avaliar o modelo.")
            else:
                st.error("Erro ao preparar sequ√™ncias de teste.")
    else:
        st.warning(f"Modelo {selected_model_type} ou scaler n√£o dispon√≠vel para {selected_asset_name}.")
        st.info("üí° **Dica:** Execute o treinamento do modelo primeiro.")
else:
    st.error("‚ùå N√£o foi poss√≠vel carregar os dados.")
    st.info("üí° **Dica:** Verifique se os arquivos de dados processados existem.")

# Informa√ß√µes sobre m√©tricas
with st.expander("‚ÑπÔ∏è Sobre as M√©tricas"):
    st.markdown("""
    ### M√©tricas de Avalia√ß√£o:
    
    **MSE (Mean Squared Error):**
    - M√©dia dos quadrados dos erros
    - Penaliza mais os erros grandes
    - Valores menores s√£o melhores
    
    **RMSE (Root Mean Squared Error):**
    - Raiz quadrada do MSE
    - Mesma unidade dos dados originais
    - Interpreta√ß√£o mais intuitiva
    
    **MAE (Mean Absolute Error):**
    - M√©dia dos valores absolutos dos erros
    - Menos sens√≠vel a outliers que RMSE
    - Valores menores s√£o melhores
    
    **R¬≤ (Coeficiente de Determina√ß√£o):**
    - Propor√ß√£o da vari√¢ncia explicada pelo modelo
    - Varia de 0 a 1 (1 = perfeito)
    - Indica qualidade do ajuste
    
    **MAPE (Mean Absolute Percentage Error):**
    - Erro percentual m√©dio
    - Facilita compara√ß√£o entre diferentes escalas
    - Valores menores s√£o melhores
    
    **Acur√°cia Direcional:**
    - % de acerto na dire√ß√£o do movimento (alta/baixa)
    - Importante para estrat√©gias de trading
    - Valores maiores s√£o melhores
    """)

st.markdown("---")
st.markdown("**MIT-510 - M√≥dulo de Avalia√ß√£o de Modelos**")
st.markdown("An√°lise detalhada da performance dos modelos de Machine Learning")